{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Modeling of King County Real Estate Sale Prices\n",
    "<b>Authors:</b> Aisha Baitemirova-Othman, Angela Kim, Steven Addison, Wahaj Dar\n",
    "\\\n",
    "<b>Instructor:</b> David Elliott\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This project analyzes residential real estate sales in King County, Washington, and uses the data to create a model that predicts price based on the parameters given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "Windermere Real Estate, based in Seattle, Washington, wants to better serve home buyers by being able to accurately present a price point using features of a house (ie. number of bedrooms) that buyers are looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "This dataset contains information about residential real estate sales in King County between May 2014 - May 2015. It includes details such as number of bedrooms and bathrooms, square footage of the home, and various features regarding location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "!pip install geopy\n",
    "import geopy\n",
    "from geopy import distance\n",
    "import plotly.express as px\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here we import our data and skim the first five rows to get a general idea of what the dataframe looks like. We also get an initial look at missing values and datatypes that need to be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/kc_house_data.csv')\n",
    "display(df.head())\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Cleaning & preparing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'id' and 'date' columns\n",
    "# Fill in missing data\n",
    "# Convert all object datatype columns to numeric\n",
    "\n",
    "df['yr_renovated'] = df['yr_renovated'].fillna(0)\n",
    "df['waterfront'] = df['waterfront'].fillna('NO')\n",
    "df['waterfront'] = df['waterfront'].str.replace('NO', '0')\n",
    "df['waterfront'] = df['waterfront'].str.replace('YES', '1')\n",
    "df['waterfront'] = pd.to_numeric(df['waterfront'])\n",
    "df['view'] = df['view'].fillna('NONE')\n",
    "df['grade'] = df['grade'].str.replace('7 Average', '7')\n",
    "df['grade'] = df['grade'].str.replace('8 Good', '8')\n",
    "df['grade'] = df['grade'].str.replace('9 Better', '9')\n",
    "df['grade'] = df['grade'].str.replace('6 Low Average', '6')\n",
    "df['grade'] = df['grade'].str.replace('10 Very Good', '10')\n",
    "df['grade'] = df['grade'].str.replace('11 Excellent', '11')\n",
    "df['grade'] = df['grade'].str.replace('5 Fair', '5')\n",
    "df['grade'] = df['grade'].str.replace('12 Luxury', '12')\n",
    "df['grade'] = df['grade'].str.replace('4 Low', '4')\n",
    "df['grade'] = df['grade'].str.replace('13 Mansion', '13')\n",
    "df['grade'] = df['grade'].str.replace('3 Poor', '3')\n",
    "df['grade'] = pd.to_numeric(df['grade'])\n",
    "if [df[df['sqft_basement'] == '?']]:\n",
    "    df['sqft_basement'] = df['sqft_living'] - df['sqft_above']\n",
    "df['sqft_basement'] = pd.to_numeric(df['sqft_basement'])\n",
    "df['bedrooms'].replace(33, 3, inplace=True)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['yr_sold'] = df['date'].dt.year\n",
    "df['house_age'] = df['yr_sold'] - df['yr_built']\n",
    "df.drop(labels=['id', 'date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding 'condition' and 'view' columns\n",
    "\n",
    "condition = df[['condition']]\n",
    "ohe = OneHotEncoder(categories=\"auto\", sparse=False, handle_unknown=\"ignore\")\n",
    "ohe.fit(condition)\n",
    "condition_enc = ohe.transform(condition)\n",
    "condition_enc = pd.DataFrame(condition_enc,\n",
    "                             columns=['cond_avg','cond_fair','cond_good','cond_poor','cond_verygood'],\n",
    "                             index=df.index)\n",
    "df.drop('condition', axis=1, inplace=True)\n",
    "df = pd.concat([df, condition_enc], axis=1)\n",
    "\n",
    "view = df[['view']]\n",
    "ohe.fit(view)\n",
    "view_enc = ohe.transform(view)\n",
    "view_enc = pd.DataFrame(view_enc,\n",
    "                        columns=['view_avg','view_excellent','view_fair','view_good','view_none'],\n",
    "                        index=df.index)\n",
    "df.drop('view', axis=1, inplace=True)\n",
    "df = pd.concat([df, view_enc], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'distance_from_bellevue' column\n",
    "\n",
    "bellevue = (47.601, -122.2015)\n",
    "\n",
    "def distancer(row):\n",
    "    coords_1 = bellevue\n",
    "    coords_2 = (row['lat'], row['long'])\n",
    "    return geopy.distance.distance(coords_1, coords_2).miles\n",
    "\n",
    "df['distance_from_bellevue'] = df.apply(distancer, axis=1)\n",
    "\n",
    "# Plot distance map\n",
    "\n",
    "distancemap = df[df['price'] <= 1000000] \n",
    "fig = px.scatter_mapbox(data_frame = distancemap, lat='lat', lon='long', color='price', color_continuous_scale='deep_r')\n",
    "fig.update_geos(resolution=50)\n",
    "fig.update_layout(mapbox_style=\"carto-darkmatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine correlations\n",
    "\n",
    "corr = df.corr()\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "corr[mask] = np.nan\n",
    "(corr\n",
    " .style\n",
    " .background_gradient(cmap='mako', axis=None, vmin=-1, vmax=1)\n",
    " .highlight_null(null_color='#f1f1f1')  # Color NaNs grey\n",
    " .set_precision(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 'sqft_living' has the highest correlation with 'price' at 0.70. We also see high multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ix = df.corr().sort_values('price', ascending=False).index\n",
    "df_sorted = df.loc[:, ix]\n",
    "\n",
    "plt.figure(figsize=(10,10), dpi=300)\n",
    "sns.heatmap(df_sorted.corr()[['price']],\n",
    "            cmap=\"mako\",\n",
    "            annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = df[['price','sqft_living','grade','sqft_above','distance_from_bellevue','view_none','house_age','zipcode']]\n",
    "heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap for presentation\n",
    "ix2 = heatmap.corr().sort_values('price', ascending=False).index\n",
    "df_sorted2 = df.loc[:, ix2]\n",
    "\n",
    "plt.figure(figsize=(10,10), dpi=300)\n",
    "sns.heatmap(df_sorted2.corr()[['price']],\n",
    "            xticklabels=['Price'],\n",
    "            yticklabels=['Price', 'Sqft Living', 'Grade', 'Sqft Above Ground',\n",
    "                         'Zipcode', 'House Age', 'No View', 'Distance from Bellevue'],\n",
    "            cmap=\"mako\",\n",
    "            annot=True)\n",
    "plt.yticks(rotation=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Scatter matrix\n",
    "\n",
    "scatter_columns = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n",
    "                   'floors', 'waterfront', 'grade', 'sqft_above', 'sqft_basement',\n",
    "                   'yr_built', 'zipcode', 'lat', 'long', 'sqft_living15','sqft_lot15']\n",
    "\n",
    "df_scatter = df[scatter_columns]\n",
    "\n",
    "sns.pairplot(df_scatter, corner=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Scatter matrix shows many non-normal distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferential Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing OLS results\n",
    "\n",
    "outcome = 'price'\n",
    "dfx = df.drop('price', axis=1)\n",
    "predictors = '+'.join(dfx.columns)\n",
    "formula = outcome + '~' + predictors\n",
    "model = ols(formula=formula, data=df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The p-values for 'floors' and 'sqft_lot15' are not statistically significant. JB is very high, indicating non-normal distributions. There is strong multicollinearity.\n",
    "\n",
    "> Previously, we saw that 'price' and 'sqft_living' have the strongest correlation, but the scatter matrix reveals that they are not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS between 'price' and 'sqft_living'\n",
    "f = 'price~sqft_living'\n",
    "model = ols(f, df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "fig = sm.graphics.plot_regress_exog(model, 'sqft_living', fig=fig);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plots show heteroscedasticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = 'price~distance_from_bellevue'\n",
    "model = ols(f, df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "fig = sm.graphics.plot_regress_exog(model, \"distance_from_bellevue\", fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing distribution using log transformation\n",
    "\n",
    "df0 = df.copy()\n",
    "df0['price_log'] = np.log(df0['price'])\n",
    "df0['sqft_living_log'] = np.log(df0['sqft_living'])\n",
    "df0 = df0.drop(['price', 'sqft_living'], axis=1)\n",
    "\n",
    "# OLS between 'price_log' and 'sqft_living_log'\n",
    "\n",
    "f = 'price_log~sqft_living_log'\n",
    "model = ols(f, df0).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "fig = sm.graphics.plot_regress_exog(model, 'sqft_living_log', fig=fig);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> When 'price' and 'sqft_living' undergo log transformation, they are more normally distributed and more homoscedastic, making them better for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Baseline Model & First Simple Linear Regression Model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df0 has original price & sqft_living removed, has price_log & sqft_living_log\n",
    "X = df0[['sqft_living_log']]\n",
    "y = df0[['price_log']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# baseline\n",
    "baseline = DummyRegressor()\n",
    "baseline.fit(X_train, y_train)\n",
    "print('Baseline Train R\\u00b2:', baseline.score(X_train, y_train))\n",
    "print('Baseline Test R\\u00b2:', baseline.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# simple lr\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_hat_train = lr.predict(X_train)\n",
    "y_hat_test = lr.predict(X_test)\n",
    "train_rmse = mse(y_train, y_hat_train, squared=False)\n",
    "test_rmse = mse(y_test, y_hat_test, squared=False)\n",
    "print('Simple LR Train R\\u00b2:', lr.score(X_train, y_train))\n",
    "print('Simple LR Test R\\u00b2:', lr.score(X_test, y_test))\n",
    "print('Simple LR Train RMSE:', train_rmse)\n",
    "print('Simple LR Test RMSE:', test_rmse)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "plt.scatter(y_test_pred, y_test)\n",
    "plt.scatter(y_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>First Multiple Linear Regression Model</b>\n",
    "\\\n",
    "Model with all untouched predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = original df\n",
    "df1 = df.copy()\n",
    "X1 = df1.drop(['price'], axis=1)\n",
    "y1 = df1[['price']]\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1)\n",
    "lr1 = LinearRegression()\n",
    "lr1.fit(X1_train, y1_train)\n",
    "y1_hat_train = lr1.predict(X1_train)\n",
    "y1_hat_test = lr1.predict(X1_test)\n",
    "train1_rmse = mse(y1_train, y1_hat_train, squared=False)\n",
    "test1_rmse = mse(y1_test, y1_hat_test, squared=False)\n",
    "print('LR1 Train R\\u00b2:', lr1.score(X1_train, y1_train))\n",
    "print('LR1 Test R\\u00b2:', lr1.score(X1_test, y1_test))\n",
    "print('LR1 Train RMSE:', train1_rmse)\n",
    "print('LR1 Test RMSE:', test1_rmse)\n",
    "y1_test_pred = lr1.predict(X1_test)\n",
    "plt.scatter(y1_test_pred, y1_test)\n",
    "plt.scatter(y1_test, y1_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There are outliers in our dataset affecting our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.histplot(df['price'], kde=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.histplot(df['sqft_living'], kde=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(15,8))\n",
    "sns.histplot(df['distance_from_bellevue'], kde=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Second Multiple Linear Regression Model</b>\n",
    "\\\n",
    "Model with price, sqft_living, distance_from_bellevue, and other continuous variable outliers removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_low = df1[\"price\"].quantile(0.023)\n",
    "price_hi = df1[\"price\"].quantile(0.977)\n",
    "\n",
    "sqft_low = df1['sqft_living'].quantile(0.023)\n",
    "sqft_hi = df1['sqft_living'].quantile(0.977)\n",
    "\n",
    "distance_hi = df1['distance_from_bellevue'].quantile(0.99)\n",
    "\n",
    "df2 = df1.copy()\n",
    "df2 = df2[(df2[\"price\"] < price_hi) & (df2[\"price\"] > price_low)]\n",
    "df2 = df2[(df2['sqft_living'] < sqft_hi) & (df2['sqft_living'] > sqft_low)]\n",
    "df2 = df2[(df2['distance_from_bellevue'] < distance_hi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X2 = df2.drop(['price'], axis=1)\n",
    "y2 = df2[['price']]\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2)\n",
    "lr2 = LinearRegression()\n",
    "lr2.fit(X2_train, y2_train)\n",
    "y2_hat_train = lr2.predict(X2_train)\n",
    "y2_hat_test = lr2.predict(X2_test)\n",
    "train2_rmse = mse(y2_train, y2_hat_train, squared=False)\n",
    "test2_rmse = mse(y2_test, y2_hat_test, squared=False)\n",
    "print('LR2 Train R\\u00b2:', lr2.score(X2_train, y2_train))\n",
    "print('LR2 Test R\\u00b2:', lr2.score(X2_train, y2_train))\n",
    "print('LR2 Train RMSE:', train2_rmse)\n",
    "print('LR2 Test RMSE:', test2_rmse)\n",
    "y2_test_pred = lr2.predict(X2_test)\n",
    "plt.scatter(y2_test_pred, y2_test)\n",
    "plt.scatter(y2_test, y2_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Third Multiple Linear Regression Model</b>\n",
    "\\\n",
    "Second model with log transformed price, sqft_living, and distance_from_bellevue, and other continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()\n",
    "df3['price_log'] = np.log(df2['price'])\n",
    "df3['sqft_living_log'] = np.log(df3['sqft_living'])\n",
    "df3['distance_from_bellevue_log'] = np.log(df3['distance_from_bellevue'])\n",
    "df3['sqft_lot_log'] = np.log(df2['sqft_lot'])\n",
    "df3 = df3.drop(['price', 'sqft_living', 'distance_from_bellevue','sqft_lot'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = df3.drop(['price_log'], axis=1)\n",
    "y3 = df3[['price_log']]\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3)\n",
    "lr3 = LinearRegression()\n",
    "lr3.fit(X3_train, y3_train)\n",
    "y3_hat_train = lr3.predict(X3_train)\n",
    "y3_hat_test = lr3.predict(X3_test)\n",
    "train3_rmse = mse(y3_train, y3_hat_train, squared=False)\n",
    "test3_rmse = mse(y3_test, y3_hat_test, squared=False)\n",
    "print('LR3 Train R\\u00b2:', lr3.score(X3_train, y3_train))\n",
    "print('LR3 Test R\\u00b2:', lr3.score(X3_test, y3_test))\n",
    "print('LR3 Train RMSE:', train3_rmse)\n",
    "print('LR3 Test RMSE:', test3_rmse)\n",
    "y3_test_pred = lr3.predict(X3_test)\n",
    "plt.scatter(y3_test_pred, y3_test)\n",
    "plt.scatter(y3_test, y3_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fourth Multiple Linear Regression Model</b>\n",
    "\\\n",
    "Third model with multicollinear variables removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df3.corr()\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "corr[mask] = np.nan\n",
    "(corr\n",
    " .style\n",
    " .background_gradient(cmap='mako', axis=None, vmin=-1, vmax=1)\n",
    " .highlight_null(null_color='#f1f1f1')  # Color NaNs grey\n",
    " .set_precision(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df4 = df3[['price_log', 'sqft_living_log', 'distance_from_bellevue_log', 'bedrooms', 'sqft_lot_log',\n",
    "          'waterfront', 'yr_renovated', 'house_age', 'view_none']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df4.corr()\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "corr[mask] = np.nan\n",
    "(corr\n",
    " .style\n",
    " .background_gradient(cmap='mako', axis=None, vmin=-1, vmax=1)\n",
    " .highlight_null(null_color='#f1f1f1')  # Color NaNs grey\n",
    " .set_precision(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = df4.drop(['price_log'], axis=1)\n",
    "y4 = df4[['price_log']]\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4)\n",
    "lr4 = LinearRegression()\n",
    "lr4.fit(X4_train, y4_train)\n",
    "y4_hat_train = lr4.predict(X4_train)\n",
    "y4_hat_test = lr4.predict(X4_test)\n",
    "train4_rmse = mse(y4_train, y4_hat_train, squared=False)\n",
    "test4_rmse = mse(y4_test, y4_hat_test, squared=False)\n",
    "print('LR4 Train R\\u00b2:', lr4.score(X4_train, y4_train))\n",
    "print('LR4 Test R\\u00b2:', lr4.score(X4_test, y4_test))\n",
    "print('LR4 Train RMSE:', train4_rmse)\n",
    "print('LR4 Test RMSE:', test4_rmse)\n",
    "y4_test_pred = lr4.predict(X4_test)\n",
    "plt.scatter(y4_test_pred, y4_test)\n",
    "plt.scatter(y4_test, y4_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fifth Multiple Linear Regression Model</b>\n",
    "\\\n",
    "Fourth model with several predictor variables scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.copy()\n",
    "col_names = ['sqft_living_log', 'distance_from_bellevue_log', 'sqft_lot_log',\n",
    "            'yr_renovated','house_age']\n",
    "features = df5[col_names]\n",
    "scaler = StandardScaler().fit(features.values)\n",
    "features = scaler.transform(features.values)\n",
    "df5[col_names] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5 = df5.drop(['price_log'], axis=1)\n",
    "y5 = df5[['price_log']]\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(X5, y5)\n",
    "lr5 = LinearRegression()\n",
    "lr5.fit(X5_train, y5_train)\n",
    "y5_hat_train = lr5.predict(X5_train)\n",
    "y5_hat_test = lr5.predict(X5_test)\n",
    "train5_rmse = mse(y5_train, y5_hat_train, squared=False)\n",
    "test5_rmse = mse(y5_test, y5_hat_test, squared=False)\n",
    "print('LR5 Train R\\u00b2:', lr5.score(X5_train, y5_train))\n",
    "print('LR5 Test R\\u00b2:', lr5.score(X5_test, y5_test))\n",
    "print('LR5 Train RMSE:', train5_rmse)\n",
    "print('LR5 Test RMSE:', test5_rmse)\n",
    "y5_test_pred = lr5.predict(X5_test)\n",
    "plt.scatter(y5_test_pred, y5_test)\n",
    "plt.scatter(y5_test, y5_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selector = RFE(lr5, n_features_to_select=4)\n",
    "selector = selector.fit(X5, y5)\n",
    "print(selector.support_)\n",
    "display(X5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Selector selects sqft_living_log, distance_from_bellevue_log, waterfront, & view_none."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Sixth Multiple Linear Regression Model</b>\n",
    "\\\n",
    "Fifth model using recursive feature elimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5.copy()\n",
    "X6 = df6[['sqft_living_log', 'distance_from_bellevue_log', 'waterfront', 'view_none']]\n",
    "y6 = df6[['price_log']]\n",
    "X6_train, X6_test, y6_train, y6_test = train_test_split(X6, y6)\n",
    "lr6 = LinearRegression()\n",
    "lr6.fit(X6_train, y6_train)\n",
    "y6_hat_train = lr6.predict(X6_train)\n",
    "y6_hat_test = lr6.predict(X6_test)\n",
    "train6_rmse = mse(y6_train, y6_hat_train, squared=False)\n",
    "test6_rmse = mse(y6_test, y6_hat_test, squared=False)\n",
    "print('LR6 Train R\\u00b2:', lr6.score(X6_train, y6_train))\n",
    "print('LR6 Test R\\u00b2:', lr6.score(X6_test, y6_test))\n",
    "print('LR6 Train RMSE:', train6_rmse)\n",
    "print('LR6 Test RMSE:', test6_rmse)\n",
    "y6_test_pred = lr6.predict(X6_test)\n",
    "plt.scatter(y6_test_pred, y6_test)\n",
    "plt.scatter(y6_test, y6_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Seventh Multiple Linear Regression Model</b>\n",
    "\\\n",
    "Sixth model using stepwise selection to choose significant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "result = stepwise_selection(X5, y5, verbose=True)\n",
    "print('resulting features:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df6.copy()\n",
    "X7 = df7[['sqft_living_log', 'distance_from_bellevue_log', 'waterfront', 'view_none']]\n",
    "y7 = df7[['price_log']]\n",
    "X7_train, X7_test, y7_train, y7_test = train_test_split(X7, y7)\n",
    "lr7 = LinearRegression()\n",
    "lr7.fit(X7_train, y7_train)\n",
    "y7_hat_train = lr7.predict(X7_train)\n",
    "y7_hat_test = lr7.predict(X7_test)\n",
    "train7_rmse = mse(y7_train, y7_hat_train, squared=False)\n",
    "test7_rmse = mse(y7_test, y7_hat_test, squared=False)\n",
    "print('LR7 Train R\\u00b2:', lr7.score(X7_train, y7_train))\n",
    "print('LR7 Test R\\u00b2:', lr7.score(X7_test, y7_test))\n",
    "print('LR7 Train RMSE:', train7_rmse)\n",
    "print('LR7 Test RMSE:', test7_rmse)\n",
    "y7_test_pred = lr7.predict(X7_test)\n",
    "plt.scatter(y7_test_pred, y7_test)\n",
    "plt.scatter(y7_test, y7_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "baseline = baseline.score(X_train, y_train)\n",
    "simple = lr.score(X_train, y_train)\n",
    "first = lr1.score(X1_train, y1_train)\n",
    "second = lr2.score(X2_train, y2_train)\n",
    "third = lr3.score(X3_train, y3_train)\n",
    "fourth = lr4.score(X4_train, y4_train)\n",
    "fifth = lr5.score(X5_train, y5_train)\n",
    "sixth = lr6.score(X6_train, y6_train)\n",
    "seventh = lr7.score(X7_train, y7_train)\n",
    "\n",
    "barchart = pd.DataFrame({'Model':['baseline', 'simple', 'first', 'second',\n",
    "                                  'third', 'fourth', 'fifth', 'sixth', 'seventh'],\n",
    "                         'R\\u00b2':[baseline, simple, first, second, third, fourth, fifth, sixth, seventh]})\n",
    "plt.figure(figsize=(15,10), dpi=300)\n",
    "ax = sns.barplot(x=barchart['Model'], y=barchart['R\\u00b2'], palette=\"mako\")\n",
    "plt.title(\"Models with their R\\u00b2 Values\", fontsize=20)\n",
    "ax.set_xlabel('Model Number', fontsize=16)\n",
    "ax.set_ylabel('R\\u00b2 Value', fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr6.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdf = pd.DataFrame({'Predictor':['Sqft Living', 'Distance From Bellevue', 'Waterfront Property', 'No View'],\n",
    "                       'Coefficient':[0.23807778, -0.20044333,  0.42040876, -0.20787165]})\n",
    "plotdf = plotdf.sort_values(by=['Coefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10), dpi=300)\n",
    "ax = sns.barplot(x=plotdf['Predictor'], y=plotdf['Coefficient'], palette=\"mako\")\n",
    "plt.title('Top House Price Predictors', fontsize=20)\n",
    "ax.set_xlabel('Predictor', fontsize=16)\n",
    "ax.set_ylabel('Coefficient', fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
